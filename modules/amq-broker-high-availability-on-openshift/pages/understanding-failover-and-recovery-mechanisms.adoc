= Understanding Failover and Recovery Mechanisms

When deploying message brokers like AMQ Broker in a production environment, ensuring continuous availability and reliability is paramount. *Failover* and *recovery mechanisms* are critical concepts that address how the system gracefully handles unexpected broker failures and ensures that client applications can maintain connectivity and continue their operations with minimal disruption.

=== Technical Explanation: Automatic Client Failover

AMQ Broker, leveraging its foundation in Apache ActiveMQ Artemis, provides robust *automatic client failover* capabilities. This feature is designed to make clients resilient to broker outages without requiring complex manual reconnection logic in the application code.

When a client initially connects to an AMQ Broker cluster configured for High Availability (HA), it receives information about all available *master* (live) and *slave* (backup) brokers within the cluster. This topology information is crucial for enabling failover.

The core mechanism works as follows:

*   *Detection of Failure*: Clients continuously monitor their connection to the active broker. If a client does not receive any packets from the broker within a pre-configured period of time (often referred to as a "liveness check" or "idle timeout"), it detects a connection failure.
*   *Failover Trigger*: Upon detecting a connection failure, the client attempts to reconnect. If *automatic failover* is enabled (i.e., `ha=true` and `reconnectAttempts` is greater than `0` in the client's connection URI), the client will use the topology information it previously received to try connecting to a designated *slave* broker.
*   *Slave Broker Activation and Session Recreation*: When the client successfully reconnects to a slave broker that has taken over the role of the failed master, the slave broker automatically re-creates any sessions, producers, and consumers that existed on the connection before the failover event. This process aims to restore the client's operational state as closely as possible.

[NOTE]
Failover occurs only if `ha=true` and `reconnectAttempts` is greater than `0`. Crucially, the client *must* successfully establish an initial connection to a master broker to receive information about all other brokers in the cluster. Without this initial handshake, the client lacks the necessary topology information to perform an intelligent failover to another *different* broker.

==== Limitations and Considerations During Failover

While automatic failover greatly simplifies application design, it's important to understand its inherent limitations:

*   *In-flight Messages*: When a failover occurs, any messages that were "in-flight" (i.e., sent by a producer but not yet acknowledged by the broker, or dispatched by the broker but not yet acknowledged by a consumer) at the exact moment of failure might be lost. This is because the new slave broker takes over at a specific point in time and does not have knowledge of these partial operations on the previous master.
*   *Session Knowledge*: Similarly, the recreated sessions on the slave broker might not have complete knowledge of all prior operations, such as messages already sent or acknowledged.
*   *Initial Connection Failures*: During the *initial connection attempt* to an AMQ Broker cluster, if the specified broker in the connection URI fails before the client can establish a connection and receive the full cluster topology, the client cannot "failover" to another broker in the traditional sense. In this specific scenario, the client can only retry to re-establish the initial connection to the *same* specified broker a configurable number of times. If all attempts fail, an exception is thrown.

==== Recovery Mechanisms and Guaranteeing Message Delivery

Despite the limitations during failover, AMQ Broker and client applications can employ several strategies to ensure robust message delivery guarantees:

*   *Automatic Session Recreation*: As mentioned, the slave broker automatically re-creates client sessions and consumers. This is the primary recovery mechanism at the broker level for continuity.
*   *Duplicate Detection*: To achieve "once and only once" delivery guarantees, even with potential message loss during failover, applications should implement *duplicate detection*. This involves assigning unique identifiers to messages and storing them in a persistent data store. If a message is re-sent after a failover, the consumer can check if it has already processed that message ID and discard duplicates.
*   *Transactional Messaging*: Using *JMS transactions* (or equivalent protocol transactions) is a powerful way to ensure atomic operations. If a failover occurs mid-transaction, the transaction is typically rolled back. The client application can then retry the entire transaction on the new broker, guaranteeing that messages are either fully processed or not processed at all, preventing partial updates.
*   *Configurable Reconnection Attempts*: Clients can be configured with a specific number of reconnection attempts and a retry interval. This allows applications to be resilient to transient network issues or short broker restart cycles.

=== Hands-on Activity: Simulating Failover and Observing Recovery

This conceptual lab activity demonstrates how a client application handles broker failure and recovers using automatic failover.

==== Prerequisites

*   An OpenShift cluster with the AMQ Broker Operator installed.
*   An AMQ Broker instance deployed in High Availability (HA) mode (e.g., a live-backup pair or a replicated cluster). This requires a `broker.yaml` Custom Resource (CR) configured with `highAvailability: true` and appropriate persistence.
*   A simple client application (e.g., a Java application using the AMQ Core Protocol or JMS) configured to connect to the HA broker. The client connection URI must include `ha=true` and `reconnectAttempts` set to a value greater than `0`.

==== Lab Steps

.  **Deploy an HA AMQ Broker Instance**:
    *   Ensure you have an AMQ Broker deployed in a highly available configuration on OpenShift. This typically involves a `Broker` Custom Resource (CR) definition that sets `highAvailability` to `true` and defines persistent storage.
    *   Verify that both the live and backup broker pods are running and healthy.

    [source,yaml]
    ----
    apiVersion: broker.amq.io/v1beta1
    kind: Broker
    metadata:
      name: my-ha-broker
    spec:
      deploymentPlan:
        size: 2 # Or 1 with ha: true for shared-store live-backup
        image: 'registry.redhat.io/amq7/amq-broker-rhel8:7.11'
        highAvailability: true
        persistenceEnabled: true
        storage:
          size: 1Gi
          storageClassName: ocs-storagecluster-cephfs # Example for OpenShift Data Foundation
    ---
    # Define a client application Deployment and Service that connects to this broker
    # (Details omitted for brevity, assuming existing knowledge of client deployment)
    ----

.  **Deploy and Run a Client Application**:
    *   Deploy your producer and consumer client applications to OpenShift. These applications should be configured to connect to your HA broker's service.
    *   Ensure the client's connection string includes the necessary failover parameters.

    [source,java]
    ----
    // Example Java JMS client connection URI
    String connectionUri = "tcp://my-ha-broker-svc:61616?ha=true&reconnectAttempts=60&reconnectDelay=500";

    // ... create connection, session, producer, consumer
    ----
    *   Start the client applications. Observe them sending and receiving messages.

.  **Simulate a Broker Failure**:
    *   Identify the currently active (live) broker pod using the Hawtio console or by inspecting broker logs/routes.
    *   Manually delete the active broker pod on OpenShift.

    [source,bash]
    ----
    oc delete pod <live-broker-pod-name> -n <your-project>
    ----

.  **Observe Client Failover and Recovery**:
    *   Monitor the logs of your client applications.
    *   You should observe the client momentarily losing connection, then logging messages indicating a successful reconnection to the newly activated backup broker.
    *   Verify that message production and consumption resume without manual intervention.
    *   Observe OpenShift automatically spinning up a new backup broker pod to replace the one you deleted, ensuring the HA configuration is restored.

.  **Verify Message Persistence (Optional, for advanced HA)**:
    *   If you had messages in queues before the failover, verify they are still available and processed by the consumer after the failover. This demonstrates the persistence and data replication aspects of HA.

This activity visually demonstrates the resilience provided by AMQ Broker's automatic client failover, highlighting how applications can seamlessly recover from broker failures within an HA setup.
